{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK-1 B**"
      ],
      "metadata": {
        "id": "hJ2fSmJGjikf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A-3GVIE3jaqR"
      },
      "outputs": [],
      "source": [
        "categories = {\n",
        "    \"Technology\": [\n",
        "        \"https://techcrunch.com\",\n",
        "        \"https://thenextweb.com\",\n",
        "        \"https://www.wired.com\"\n",
        "    ],\n",
        "    \"Health\": [\n",
        "        \"https://www.medicalnewstoday.com\",\n",
        "        \"https://www.healthline.com\",\n",
        "        \"https://www.webmd.com\"\n",
        "    ],\n",
        "    \"Sports\": [\n",
        "        \"https://www.espn.com\",\n",
        "        \"https://www.bbc.com/sport\",\n",
        "        \"https://www.sportskeeda.com\"\n",
        "    ],\n",
        "    \"Finance\": [\n",
        "        \"https://www.investopedia.com\",\n",
        "        \"https://www.forbes.com\",\n",
        "        \"https://www.bloomberg.com\"\n",
        "    ],\n",
        "    \"Science\": [\n",
        "        \"https://www.sciencenews.org\",\n",
        "        \"https://www.scientificamerican.com\",\n",
        "        \"https://www.nature.com\"\n",
        "    ],\n",
        "    \"Entertainment\": [\n",
        "        \"https://www.hollywoodreporter.com\",\n",
        "        \"https://www.variety.com\",\n",
        "        \"https://www.rottentomatoes.com\"\n",
        "    ],\n",
        "    \"Politics\": [\n",
        "        \"https://www.politico.com\",\n",
        "        \"https://www.nbcnews.com/politics\",\n",
        "        \"https://www.reuters.com/politics\"\n",
        "    ],\n",
        "    \"Education\": [\n",
        "        \"https://www.edutopia.org\",\n",
        "        \"https://www.timeshighereducation.com\",\n",
        "        \"https://www.theguardian.com/education\"\n",
        "    ],\n",
        "    \"Travel\": [\n",
        "        \"https://www.lonelyplanet.com\",\n",
        "        \"https://www.travelandleisure.com\",\n",
        "        \"https://www.nationalgeographic.com/travel\"\n",
        "    ],\n",
        "    \"Gaming\": [\n",
        "        \"https://www.pcgamer.com\",\n",
        "        \"https://www.ign.com\",\n",
        "        \"https://www.gamespot.com\"\n",
        "    ],\n",
        "    \"Automobile\": [\n",
        "        \"https://www.caranddriver.com\",\n",
        "        \"https://www.motortrend.com\",\n",
        "        \"https://www.autoblog.com\"\n",
        "    ],\n",
        "    \"Fashion\": [\n",
        "        \"https://www.vogue.com\",\n",
        "        \"https://www.elle.com\",\n",
        "        \"https://www.gq.com\"\n",
        "    ],\n",
        "    \"Food\": [\n",
        "        \"https://www.bonappetit.com\",\n",
        "        \"https://www.foodnetwork.com\",\n",
        "        \"https://www.epicurious.com\"\n",
        "    ],\n",
        "    \"Cryptocurrency\": [\n",
        "        \"https://www.coindesk.com\",\n",
        "        \"https://cointelegraph.com\",\n",
        "        \"https://www.cryptoslate.com\"\n",
        "    ],\n",
        "    \"History\": [\n",
        "        \"https://www.history.com\",\n",
        "        \"https://www.bbc.co.uk/history\",\n",
        "        \"https://www.smithsonianmag.com/history\"\n",
        "    ],\n",
        "    \"Environment\": [\n",
        "        \"https://www.nationalgeographic.com/environment\",\n",
        "        \"https://www.sciencedaily.com/news/earth_climate\",\n",
        "        \"https://www.worldwildlife.org\"\n",
        "    ],\n",
        "    \"Movies\": [\n",
        "        \"https://www.imdb.com\",\n",
        "        \"https://www.boxofficemojo.com\",\n",
        "        \"https://www.fandango.com\"\n",
        "    ],\n",
        "    \"Artificial Intelligence\": [\n",
        "        \"https://www.analyticsvidhya.com\",\n",
        "        \"https://www.aitrends.com\",\n",
        "        \"https://www.deepmind.com\"\n",
        "    ],\n",
        "    \"Cybersecurity\": [\n",
        "        \"https://www.darkreading.com\",\n",
        "        \"https://www.csoonline.com\",\n",
        "        \"https://www.bleepingcomputer.com\"\n",
        "    ],\n",
        "    \"Business\": [\n",
        "        \"https://www.wsj.com\",\n",
        "        \"https://www.businessinsider.com\",\n",
        "        \"https://hbr.org\"\n",
        "    ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# Create directory for output\n",
        "os.makedirs(\"scraped_data\", exist_ok=True)\n",
        "\n",
        "def extract_date(soup):\n",
        "    \"\"\"Extract article date from meta tags.\"\"\"\n",
        "    date_tags = [\"article:published_time\", \"date\", \"publish-date\", \"pubdate\"]\n",
        "    for tag in date_tags:\n",
        "        date_meta = soup.find(\"meta\", {\"property\": tag}) or soup.find(\"meta\", {\"name\": tag})\n",
        "        if date_meta and date_meta.get(\"content\"):\n",
        "            return date_meta[\"content\"]\n",
        "    return datetime.today().strftime(\"%Y-%m-%d\")  # Default to today's date\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Cleans text by removing unnecessary spaces and line breaks.\"\"\"\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Normalize whitespace\n",
        "    return text.strip()\n",
        "\n",
        "def scrape_and_save(category, urls):\n",
        "    structured_data = []\n",
        "\n",
        "    for url in urls:\n",
        "        try:\n",
        "            response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            title = soup.title.string.strip() if soup.title else \"Untitled Article\"\n",
        "            date = extract_date(soup)\n",
        "            paragraphs = [p.get_text(strip=True) for p in soup.find_all(\"p\")]\n",
        "            content = \"\\n\".join(paragraphs)\n",
        "\n",
        "            structured_data.append(f\"=== {title} ===\\nDate: {date}\\nSource: {url}\\n--------------------\\n{clean_text(content)}\\n\\n\")\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error scraping {url}: {e}\")\n",
        "\n",
        "    file_path = os.path.join(\"scraped_data\", f\"{category}111.txt\")\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.writelines(structured_data)\n",
        "\n",
        "    print(f\"Structured data saved for category: {category}\")\n",
        "\n",
        "\n",
        "\n",
        "# Scrape data\n",
        "for category, urls in categories.items():\n",
        "    scrape_and_save(category, urls)\n"
      ],
      "metadata": {
        "id": "yn-VQ21ZjsMj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}